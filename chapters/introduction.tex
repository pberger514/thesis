\chapter{\label{chap:intro} Introduction}

The measurement of the anisotropy spectrum of the Cosmic Microwave Background (CMB) has ushered in the Era of Precision Cosmology, where percent-level determination of the content of our Universe and its evolution history can probe physics at energy scales orders of magnitude higher than those currently reached at the LHC \citep{planckcosmo, planckxbicep}. It has become clear, however, that the audacious goals of modern observational cosmology will require more statistical power than is contained in the primary CMB's two-dimensional surface. In order to gain understanding into the nature of Dark Energy, gravity on large scales, the physics of inflation and very early times, and the neutrino mass hierarchy we must look to the full three-dimensional volume of our observable universe. 

Meanwhile, traditional photometric and spectroscopic galaxy surveys have reached a sufficient level of maturity to complement the precision of CMB experiments. Large-scale structure techniques such as Baryon Acoustic Oscillations (BAO) \citep{boss}, weak gravitational lensing \citep{cfhtlens, kids450}, and redshift-space distortions \citep{rsd}, in combination with CMB and distance ladder measurements, have placed stringent constraints on the flat $\Lambda$CDM Standard Model of Cosmology. Furthermore, several interesting anomalies have been identified between these datasets which may point to new physics \citep{planckcosmo, h0}. However, these surveys by definition select only the galaxies that are bright enough to be detected individually, and so generically have been designed to target either large sky area coverage or depth.

The technique of Line-Intensity Mapping (LIM) has emerged as a promising new frontier in this regard \citep{statusreport}, where instead the angular resolution needed to identify individual galaxies is sacrificed, and the large-scale, integrated emission from \textit{all} sources of flux is collected into an intensity map. One can then exploit the redshifting of spectral line emission from these sources, by designing an experiment with increased spectral resolution, to obtain a tomographic three-dimensional image of the large-scale structure.

In particular, the 21 cm line emission from the spin-flip transition of neutral hydrogen (HI) has received great interest recently, with several mature experiments having detected or constrained its emission at various redshifts, and numerous new radio telescopes planned or under-construction worldwide to target it. The 21 cm line is the lowest energy spectroscopic transition and is therefore an isolated spectral line. As hydrogen is the most abundant element in the universe, HI should trace the Universe's large-scale structure from the emission of the CMB until today. At moderate to low redshifts, the 21 cm line has been detected in cross-correlation with various spectroscopic galaxy surveys by the Green Bank Telescope \citep{changetal, masuietalgbt, switzeretalgbt, andersonetalparkes}. Telescopes such as BINGO, CHIME, HIRAX, Tianlai, and MeerKAT/SKA1-MID are currently targeting detection of the Baryon Acoustic Oscillations and thus tomographic constraints on the time evolution of Dark Energy. Furthermore, at higher redshifts, 21 cm LIM promises to image the onset of star formation and the transition from a neutral to ionized universe, dubbed the Cosmic Dawn and Epoch of Reionization, respectively. Several facilities such as the GMRT, PAPER, LOFAR, and the MWA have placed interesting constraints on the power spectrum of the ionization fluctuations. These and many others, including the US-based telescopes HERA \citep{hera} and the Owens Valley LWA, are well-poised for a detection.

Despite this multiplicity of experiments planned or in progress, redshifted 21 cm emission has only been detected, a handful of times, in cross-correlation with optical galaxy surveys. This is due largely to residual contamination from both terrestrial sources of radio-frequency interference and astrophysical foregrounds, notably the synchrotron emission of the Milky Way which can be some $\sim 10^5$ times brighter than the HI signal. It is now understood that mitigation of these systematics imposes strict requirements on both instrumental control and data analysis techniques. These requirements have instituted a new philosophy of ``end-to-end modelling'' in the field: Whereby the underlying signal, astrophysical foregrounds, telescope, and receiving electronics are simulated together in feedback with the data.

In this thesis, we describe the development of end-to-end analysis and modelling techniques for 21 cm line intensity mapping. At minimum, an end-to-end simulation pipeline requires a signal component as input, a systematic which has some effect on the signal, and a statistic or metric by which to measure the effect. The following chapters describe developments in each of these sections of the pipeline, focused (but not exclusive) towards the CHIME Pathfinder telescope, ordered by their flow through the pipeline. In Chapter \ref{chap:signal}, we describe a novel subgrid biasing scheme for dark matter halo catalogs produced with the Peak Patch algorithm, and its application to accurate modeling of the intensity mapping signal component. The systematic focused on in this thesis is the angular response function, or ``beam,'' of the interferometer. Chapter \ref{chap:hol}, describes the radio holography technique implemented to measure this function for each of the CHIME Pathfinder's 256 antennas. Once the beam is known it can be deconvolved from images. The conversion of time ordered data to full-sky images, deconvolution, and cleaning thereof is the topic of Chapter \ref{chap:mapmaking}. However first, in Section \ref{sec:bg}, we give further detail into the background and motivation for each of the chapters.

\section{\label{sec:bg} Background and relevance to previous work}

\subsection{\label{sec:bg:subsec:signal} Modelling the intensity mapping signal}

The first detection of the redshifted 21 cm emission in the intensity mapping regime was demonstrated by Ref. \citep{changetal}, using the Green Bank Telescope. The authors conducted a 21 cm survey spanning the redshift range of $0.53 < z < 1.12$, and achieved of proof-of-concept for the foreground excision techniques which form the basis of 21 cm LIM cosmology. The Galactic and extra-Galactic foregrounds in radio are due to largely to synchrotron emission, all of which are expected to have smooth spectral structure. This is in contrast to the 21 cm signal which should come in lumps, allowing one to perform a high-pass filter. The authors of \citep{changetal} pioneered a singular-value decomposition technique, which subtracts the dominant spectral eigenmodes from the data, and achieved a residual intensity field (and therefore an upper limit to the 21 cm brightness temperature fluctuation) of $464 \pm 277$ $\mu K$ on the pixel scale, at a mean redshift of $0.8$. The authors further reported a positive cross-correlation of the residuals with the underlying cosmic density field as traced by the DEEP2 galaxy survey, with an amplitude of $157 \pm 42$ $\mu K$. This constraint on the amplitude maps to a combination of HI abundance of the galaxies, the bias parameters $b_{HI}$, $b_{gal}$ of the HI and optical samples relative to the underlying matter density field, and the cross-correlation coefficient or ``stochasticity'' between the two datasets $r$. This work provides the first constraint on the HI abundance of the Universe $\Omega_{HI}$ from 21 cm LIM, of $\Omega_{HI}b_{HI}r = (0.66 \pm 0.18) \times 10^{-3}$ at $z = 0.8$. Follow-up deeper measurements with the GBT \citep{masuietalgbt} and cross-correlation with the WiggleZ galaxy survey \citep{switzeretalgbt} allowed for a detection of the signal at multiple scales and an improvement on this constraint to $\Omega_{HI}b_{HI}r=0.40 \pm 0.09 \times 10^{-3}$. This constitutes a $7.4\sigma$ detection of the HI cross-correlation, however a detection of the auto-power remains elusive.

Inspecting these results one understands that in the near future, with the (minimum) order-of-magnitude increase in sensitivity attributed to upcoming surveys,  proper interpretation of the 21 cm intensity mapping results will depend heavily on the modelling of the underlying astrophysics. Measurements of the amplitude of the auto- and cross-power spectra, for example, exhibit degeneracies between the parameters of interest, like the Universal abundance of HI, and ``nuisance parameters,'' like the bias and stochasticity. The latter depend sensitively on the clustering properties and astrophysics of the underlying populations. An interesting demonstration of this has been performed recently at low-redshifts \citep{andersonetalparkes}, for the first time in the intensity mapping regime, which showed that HI ``avoids'' old red galaxies and prefers young blue ones. This is a tantalizing taste of the power of 21 cm LIM to trace star formation and galaxy evolution across redshifts. 

Attempts to reconcile various large-scale tracers of the HI abundance have met with difficulty \citep{pad2015, castorina2016}, possibly due to the limitations of these over-simplified analytic models. Novel techniques such as redshift-space distortions, or others that exploit the shape of the power spectrum \citep{wolz2017}, will hope to break these degeneracies. However uncertainties yet to be properly addressed even in high resolution hydrodynamic simulations (let alone ported to the statistical limit pertinent to large-scale structure), such as supernova and AGN feedback and their effects on the ionizing background \citep{pontzenbias}, will surely complicate the process. 

\subsection{\label{sec:bg:subsec:hol} Radio Holography}

To achieve the sensitivity required to detect the diffuse emission from cosmic neutral hydrogen (HI), a $\mu K$ signal buried under terrestrial sources of interference and order $K$ astrophysical foregrounds, modern 21 cm experiments have adopted a new telescope design, of highly redundant, close-packed, interferometric arrays. Taking advantage of the operation of Moore's Law on the computational cost of correlation, telescopes such as BINGO, CHIME, HERA, HIRAX, and Tianlai have dramatically increased antenna number over their predecessors. With no moving parts, these arrays are transit telescopes, allowing the sky to drift through overhead, and employ interferometry to achieve angular resolution within their large fields of view for fast mapping speeds at relatively low cost. Combining redundant geometries, wide fields of view, large bandwidths, and high spectral resolution, they are optimized for sensitivity to spatial scales associated with the large-scale structure.

These large arrays present a daunting calibration task. Uncertainties in deconvolution of the angular response function mix the angular structure in both intensity and polarization into the frequency spectrum of previously smooth components \citep{wedge1}. This effect, known as \textit{mode mixing}, has been a topic of heavy discussion in the literature and is now understood as a central issue in a successful foreground removal. For example, Refs. \citep{mmodes1, mmodes2} introduced a linear foreground removal technique based on a KL-transform and showed that, given time stability of $1\%$ and characterization of the telescope's angular response (the beam) to $0.1\%$, a factor of $\sim2\times 10^7$ foreground reduction could be achieved. 

Chapter \ref{chap:holography} describes the use of radio holography of bright, stable point sources for obtaining high signal-to-noise measurements of the amplitude and phase of the two-dimensional primary beams of the entire CHIME Pathfinder array \citep{chimepath1}, across its frequency band. It describes the instrumental setup and data analysis techniques that were developed to collect a large sample of holographic measurements, from sources at a range of declinations, and combine these into a homogeneous estimate of the 2D CHIME Pathfinder beam. Furthermore, its details progress towards developing a first principles understanding of the interference effects which produce the beam shape. The beam model can then be used to produce maps, allowing it to be validated through its ability undo beam effects seen in the maps. This discussion is the topic Chapter of \ref{chap:mapmaking}.

\subsection{\label{sec:bg:subsec:mmodes} Bayesian Mapmaking and the $m$-mode Formalism}

The success of CMB experiments such as the Planck satellite has been accompanied by the development of sophisticated analysis techniques based on Bayesian methods \citep{bondjaffeknox}. For the CMB these have been incorporated into state-of-the-art likelihood codes (e.g. \citep{commander}), achieving optimal constraints on cosmological parameters. These are optimal in the sense that, through forward modelling of the signal and instrument, the smallest possible error bars are known, allowing for precise control over systematics.

These techniques were previously thought too costly for the massive radio interferometric datasets required for full-scale 21 cm LIM. Refs. \citep{mmodes1, mmodes2} introduced the $m$-mode formalism, which exploits spherical geometry and the day-to-day periodicity of a transit telescope's signal to achieve large computational savings, rendering optimal map making and power spectrum estimation techniques computationally tractable. More recently, we have solved a major pitfall of the method, adapting it to include non-stationary sky statistics, allowing it to tackle the most realistic and sophisticated foreground models \citep{bergeroppermann} (work towards the applicant's PhD thesis). $m$-mode based analysis pipelines are are now being pursued by CHIME, HERA, the Owens Valley LWA \citep{eastwoodetal}, HIRAX, and Tianlai.