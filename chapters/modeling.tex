\chapter{\label{chap:signal} Modeling the 21 cm line}

\newpage

\section{Introduction}
\label{ch:signal:sec:intro}

The current and upcoming generation of 21 cm Line Intensity Mapping (21 cm LIM) surveys promises a minimum order-of-magnitude increases in sensitivity, leading to the ever-elusive detection of the 21 cm auto-power spectrum. These surveys promise to offer unprecedented insights into the invovlement of neutral hydrogen (HI) in early galaxy formation and evolution, and compliment state-of-the-art galaxy survey techniques in enormous volumes of the universe.

However, it is known that cosmological parameter inference from measurements of the amplitude of the auto- and cross-power spectra exhibit degeneracies between the parameters of interest. These include astrophysical parameters like the Universal abundance of HI, and others such the bias and stochasticity, which depend sensitively on the clustering properties and astrophysics of the underlying populations, but also on the details of the survey selection functions and geometries. An interesting demonstration of this has been performed recently at low-redshifts \citep{andersonetalparkes}, for the first time in the intensity mapping regime, which showed that HI ``avoids'' old red galaxies and prefers young blue ones. This is a tantalizing taste of the power of 21 cm LIM to trace star formation and galaxy evolution across redshift.

However, modeling of the 21 cm line at intermediate redshifts is on shaky footing due not only to the difficulty of modeling a biased tracer of the non-linear matter distribution \citep{biasreview}, but also to the complicated baryonic physics involved. Recent attempts to reconcile various large-scale tracers of the HI abundance have met with difficulty \citep{pad2015, castorina2016}, possibly due to the limitations of these over-simplified analytic models. Novel techniques such as redshift-space distortions, or others that exploit the shape of the power spectrum \citep{wolz2017}, will hope to break these degeneracies, but are accompanied with their own systematics. High-resolution hydrodynamic simulations (hydro sims) suffer from resolution-dependent results, require fine-tuning of subgrid physics and feedback mechanisms, and predict a highly dynamic and variable environment for neutral hydrogen \cite{firehi} leading to complex phenomenology \citep{illustristng21cm}.

Conversely, for modern large-scale structure surveys with complicated systematics, it has become standard pratice to test data analysis pipelines on large sets of mock simulations. The number of simulations required to accurately estimate covariances is currently prohibitive for full dark matter only N-body simulations, let alone include the effects of baryons. Furthermore, for full-sky 21 cm LIM, one encounters large-scale environmental effects not yet studied in high-resolution simulations \citep{pontzenbias, tidalsims} and foreground filtering techniques which operate on the entire observed volume \cite{ffska}.

By definition, however, in LIM one does not resolve individual galaxies but only the smoothed integrated emission from all HI. Evidence from hydro sims \cite{pontzen2008, bagla2010, vn2014, illustristng21cm} suggest that halos with circular velocities above 30 km/s can sufficiently self-shield and host significant HI. This presents a significant dynamic range to be resolved in simulation. In Figure \ref{f_hi_of_mh}, we compute $f_{\rm HI}(>M_h)$, the fraction of HI in halos above some mass $M_h$, 
\begin{equation}
f_{\rm HI}(>M_h) \equiv \frac{\int_{M_h}^\infty M_{\rm HI}(M) n(M) dM}{\int_0^\infty M_{\rm HI}(M) n(M) dM}, \label{f_hi_def}
\end{equation}
where $n(M)$ is the halo mass function (HMF) and $M_{\rm HI}(M)$ is the halo mass to HI relation. For this illustration we show two parametrizations of $M_{\rm HI}(M)$: the fit to hydro sim results from \citeauthor{illustristng21cm} and the Monte-Carlo Markov Chain (MCMC) best fit to a collection of low-redshift HI galaxy surveys, intermediate redshift 21 cm LIM, and damped Lyman-alpha data from \citeauthor{pad2016}. Figure \ref{f_hi_of_mh} shows how a significant fraction of HI is expected to come from intermediate-to-low mass halos, and that halos above $10^9 M_\odot$ should host all the HI to within a few percent.
\begin{figure}[h!] % not h only
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/subgrid/f_hi_of_mh.png}%
\caption{The fraction of HI contained in halos above $M_h$, $f_{\rm HI}(>M_h)$, defined in Eq. \ref{f_hi_def}. We show the quantity for two parametrizations of the halo mass to HI mass relation, and redshifts 0, 1, 2, and 3 are coloured with decreasing darkness.}
\label{f_hi_of_mh}
\end{center}
\end{figure}
Given the low resolution (modulo spectral) of LIM experiments, it is unclear what effect this population has on the linear and quasi-linear scales relevant, for example, for the Baryon Acoustic Oscillations (BAO). It is clear, however, that given the power law scaling of the low-mass tail of the HMF, for simulation techniques the number of halos hosting HI in a cosmological volume can quickly become cumbersome.

In this work, therefore, we adopt a sub-grid scheme and model the 21 cm LIM signal as a combination of halo and continuous field components. We produce a set of high resolution cosmological simulations, which resolve the entire relevant population of dark matter halos, and use them to validate and test our sub-grid method. We employ the Peak Patch \citep{peakpatch1} method for our simulations, which we have augmented with the MUSIC multi-scale initial conditions solver allowing us the to reach the target resolution. 

This chapter is organized as follows: In Section \ref{ch:signal:sec:music}, we discuss our combination of the MUSIC and Peak Patch codes which allows us to generate coherent initial conditions on the fly. In Section \ref{ch:signal:sec:gppbs}, we present the mathematical preliminaries for our sub-grid biasing method, which is uses a Peak Background Split \citep{biasreview} estimator to measure and extrapolate the bias. In Section \ref{ch:signal:sec:sims}, we present the set of high-resolution simulations we use in Section \ref{ch:signal:sec:results} to test our method. Finally, in Section \ref{ch:signal:sec:conclusion}, we discuss our results and the implications for more accurate modeling of 21 cm LIM.

\section{Multi-Scale Initial Conditions for Peak Patch}
\label{ch:signal:sec:music}

We generate dark matter halo catalogues with the Peak Patch method, for which we provide a brief description of the relevant aspects here. For further details please refer to Refs. \citep{peakpatch1,peakpatch2,peakpatch3}. Peak Patch (PP) identifies dark matter halos from the cosmological initial conditions (Lagrangian space) by performing spherically averaged measurements of both the linear density and tidal tensor at locations of candidate peaks of the density field. A PP halo is therefore the largest spherical region of Lagrangian space which satisfies the conditions for ellipsoidal collapse at the target redshift. Therefore its spherically averaged density can be interpreted as its collapse barrier, analagous to tracing N-body halos identified in the completed simulation (Eulerian space) back to initial conditions and measuring the initial density. PP halos, though, are not purely the result of integrating the ellipsoidal collapse equations, since exclusion is enforced through a higherarchical binary merging algorithm on candidate peaks. The final halos are then moved to Eulerian space using second-order Lagrangian perturbation theory. Peak Patch has passed extensive validations against many modern simulation methods \cite{euclidcp1, euclidcp2, euclidcp3}.

In order to push the low mass resolution limit of the Peak Patch code, we have combined it with a new method for generating initial conditions (ICs). Ensuring large-scale coherence of the ICs is the most non-local step in the PP algorithm. In the standard monolithic box approach, cubic periodic ICs for the entire simulation volume are generated in a preliminary step. Parallelization across many processors is achieved using a slab domain decomposition and Fast Fourier Transforms (FFT). However, the PP calculation itself takes place in cubic sub-regions, and for large volumes a single processor is required to perform many such computations. Each processor must therefore hold a slice of the full simulation volume in its local memory to be requested at some point in the computation. While this solution is extremely fast and ideal for Monte-Carlo iteration, the global field is a considerable memory overhead and it is not well suited to non-cubic survey geometries (e.g. pencil surveys). The Multi-Scale Initial Conditions (MUSIC) \citep{music} code is an initial conditions solver for cosmological zoom-in simulations. It is designed to re-sample a high-resolution ``refinement region'' from within a previously run coarse resolution simulation, achieving $10^{-4}$ errors. MUSIC uses a multi-grid algorithm where a pre-determined grid of seeds for the pseudo-random number generator is assigned to each power of 2 refinement level. Parallelization is therefore trivial. MUSIC allows for each PP sub-domain to request its ICs on the fly, and the entire simulation volume need never be realized simultaneously. This ``streaming''-style parallelization allows processors to ``stream'' through the sub-domains one at a time, alleviating memory requirements and allowing effectively arbitrary resolution/box size (limited only by compute time).

\begin{figure}[h!] % not h only
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/subgrid/density_octants_residuals.png}%
\caption{A single-cell thick slice through the residuals of the initial density field, $\delta$, generated with 2 tiles (meaning 8 MUSIC volumes were computed independently) compared to the unigrid simulation with the same seed. We observe $\sim 10^{-4}$ errors in the density.}
\label{density_octants_residuals}
\end{center}
\end{figure}

In Figure \ref{density_octants_residuals}, we show the residuals of the initial density field, $\delta$, generated with 2 tiles (meaning 8 MUSIC volumes were computed independently) compared to the unigrid simulation with the same seed. For this visualization, we computed at 512 Mpc with 1 Mpc resolution and show a single 1 Mpc-thick slice. We observe $\sim 10^{-4}$ errors with some large-scale behaviour, however the errors are dominated by small-scale fluctuations consistent with Ref. \cite{music}. The PP computation requires a buffer region equal to radius of the largest halo one expects to find in the full simulation. This buffer is requested from MUSIC but then cut out for the visualization, which mitigates edge errors from MUSIC in the active region and accounts for the visible boundaries in Figure \ref{density_octants_residuals}.

\begin{figure}[h!] % not h only
\begin{center}
\includegraphics[width=0.6\textwidth]{figures/subgrid/pk_pp_vs_music_512Mpc_check.png}%
\caption{The power spectra of 32 Peak Patch simulations computed with MUSIC compared to unigrid initial conditions. For this test the boxes are 512 Mpc with 1 Mpc resolution at redshift 0. There are 4 MUSIC tiles meaning 64 sets of initial conditions are compute independently to produce the entire simulation volume.}
\label{pkcheck}
\end{center}
\end{figure}

In Figure \ref{pkcheck}, we compute the power spectrum of halo catalogs generated with 4 tiles (so 64 independent MUSIC volumes) as well as the standard implementation, for 32 independent realizations of each method.

\section{Extrapolating the Peak-Background Split}
\label{ch:signal:sec:epbs}

\begin{figure} % not h only
\begin{center}
\includegraphics[width=0.95\textwidth]{figures/subgrid/1Gpc_patchplot_z2_Mcut1e12_10Mpc.png}
\caption{A 10 Mpc slice of a 1 Gpc simulation at redshift 2, with 0.125 Mpc resolution. Halos above $10^{12}$ $M_\odot$ are coloured orange.}
\label{musicslice}
\end{center}
\end{figure}

To model the contribution to the 21 cm flux from the population of low-mass halos below the resolution of our simulation, we need to correctly bias the continuous field component. That is we would like to model the halo overdensity,
\begin{equation}
\delta_h(\vec{x}) \equiv \frac{n(\vec{x}) - \overline{n}}{\overline{n}},
\end{equation}
where $n(\vec{x})$ is the halo density and $\overline{n}$ is its Universal mean, as an expansion in the linear matter overdensity, $\delta(\vec{x})$. Above and in the following time dependence is supressed for simplicity but is implicit. The most general expansion consistent with stationarity, up to second order in $\delta(\vec{x})$ and up to two spatial derivatives is
\begin{equation}
\delta(\vec{x}) = b_1 \delta(\vec{x}) + \frac{b_2}{2} \left( \delta(\vec{x})^2 - \langle \delta^2 \rangle \right)+ b_{\nabla^2\delta} \left( \nabla^2\delta(\vec{x}) - \langle \nabla^2\delta \rangle \right) + b_{s^2} \left( s^2(\vec{x}) - \langle s^2 \rangle \right), \label{general_bias_exp}
\end{equation}
where
\begin{equation}
s_{ij}(\vec{x}) = \left( \frac{\partial_i \partial_j}{\nabla^2} - \frac{1}{3}\delta^{\rm K}_{ij}\right) \delta(\vec{x}),
\end{equation}
is the Lagrangian anisotropic strain tensor, $s^2(\vec{x}) = \sum_{ij} s^2_{ij}(\vec{x})$, angled brackets denote an ensemble average, and $\delta_{ij}^{\rm K}$ is Kronecker's delta. The first two $b$s in Eq. \ref{general_bias_exp} are termed local bias parameters, while those associated to spatial derivates are non-local since the derivatives introduce a dependence on the fluctuations in $\delta(\vec{x})$ about the field point in question $\vec{x}$. Several authors have reported significant detections of second (and higher)-order non-local bias parameters in Lagrangian \citep{shethetal2013, biagettietal2014, modietal2017, abidi+baldauf2018} and Eulerian space \cite{lazeyrasetal2017}.

The Peak Background Split (PBS) is a prescription for determining the bias parameters, based on the argument that an initially overdense region should host more halos. In other words, the bias parameters measure the response of the halo density to variations in the underlying continuous field. Indeed, \citeauthor{schmidt2013} show, by defining the PBS in terms of variation of the mean density of the universe (the so-called \textit{separate universe} argument), one obtains precisely the local bias expansion \citep{biasreview}. \citeauthor{modietal2017} then develop a PBS-based estimator for dark matter halo catalogs, and apply it to halos traced back to Lagrangian space from large-scale N-body simulations. Further, they generalize the work of \citeauthor{schmidt2013} to include non-local bias, and find a significant detection of negative $b_{s^2}$ for large mass halos in Lagrangian space. In this work, we are interested in extrapolating measurements of  \citeauthor{modietal2017} to small mass halos. We find the PBS-based estimator a convenient method for doing so, and so develop a slightly modified algorithm allowing us to perform the extrapolation. 

The algorthim of \citeauthor{modietal2017} proceeds by diving the simulated region, of side length $L$, into smaller boxlets, of side length $l$. The fields in question $\{\Delta\} = \{\delta(z), \delta^2(z), s^2(z)\}$ can then be averaged in the boxlets, and the average the number density of halos $N_i(\Delta M)/l^3$, where $N_i(\Delta M)$ is the number of halos in a bin $[M - \Delta M/2, M + \Delta M/2]$ in boxlet $i = 1, \dots, (L/l)^3$, can be measured. Here, $\delta(z)$ is the Lagrangian density field extrapolated to the target redshift using linear theory. The response of the distribution of halo overdensities to the averaged fields $\{\overline{\Delta}\}$ can then be fit to the relation \ref{general_bias_exp}. Of course $\left\langle \lim_{\Delta M \rightarrow 0} N(\Delta M)/l^3 \right\rangle_l = \frac{\mathrm{d}n}{\mathrm{d}M}(M)$ the halo mass function, where $\langle \rangle_l$ denotes an ensemble average over independent realizations. Therefore, our procedure is to adopt a fitting function for the halo mass function, to be fit to the large mass halo bins in each boxlet from which the low mass bias can be extrapolated.

Attempts to parametrize and measure the halo mass function in N-body simulations have met with technical difficulties. Ref. \citep{tinker2008} developped one such parametrization and in Ref. \citep{tinker2010} applied the PBS to compute an analytic expression for $b_1$ in terms of the parameters of the fitting function, but found deviations between this method and a direct fit to the bias at low masses. However, it is now understood that the mass function is sensitive to the halo finder used and futhermore it is not known whether a universal expression for the HMF such as the one sought in Ref. \citep{tinker2008} exists \citep{desjacquesetal2018}. Therefore, in targeting sub-percent accuracy on the HMF, the authors of Ref. \citep{aemulushmf} abandon a universal parametrization and use a Gaussian process model to interpolate between simulations and produce a HMF emulator.

In this work, however, we are not interested in determining a description of the abundance of halos or their response to variations of the background in all cosmologies. We simply wish to adopt a fitting function with enough flexibility to accurately fit the abundance, under changes in the background, of a given single realization. However, the function must not have too much freedom, since this would lead to overfitting and a poor extrapolation. Therefore, we adop the parametrization given in Ref. \citep{aemulushmf},
\begin{align}
\frac{\mathrm{d}n}{\mathrm{d}M} = G(\sigma)\frac{\overline{\rho}_m}{M}\frac{\mathrm{d}\ln{\sigma^{-1}}}{\mathrm{d}M}, \label{aemulus_hmf}
\end{align}
where the multiplicity function
\begin{align}
G(\sigma) = B \left[ \left( \frac{\sigma}{e}\right)^{-d} + \sigma^{-f} \right] \exp{\left( -g / \sigma^2 \right)}, \label{aemulus_G}
\end{align}
where $\{B, d, e, f, g\}$ are free parameters and $\sigma^2(M)$ is RMS variance of the density field filtered with a top hat filter on scale $R(M)$,
\begin{align}
\sigma^2(M) = \int \mathrm{d}\ln{k} \frac{k^3 P(k)}{2\pi^2} \tilde{W}(kR).
\end{align}
Indeed, this is a function of $\sigma$ directly and not only the peak height $\nu = \delta_{sc}(z)/\sigma$, where $\delta_{sc}(z)$ is the spherical collapse threshold at redshift $z$ \citep{halomodelreview}, as would be required for a universal HMF. Furthermore, this modifies the treatment of \citep{tinker2008} by adding a second parameter controlling the roll-off of the power law tail of the HMF. Since we measure the HMF in boxlets conditional on the background fields we do not require that all matter resides in halos and leave $B$ a free parameter.

%Gaussian processes are kernel-based methods, providing a Bayesian non-parametric approach for smoothing and interpolation in noisy datasets \citep{rasmussenandwilliams}, but which recently have received increased interest as a supervised machine learning technique capable of feature extraction and extrapolation \citep{wilsonandadams}. A distribution of functions $f(x)$ is a Gaussian process if it is completely described by its mean $m(x) = \langle f(x) \rangle$ and a covariance $\mathrm{cov}[f(x), f(x')] = \left\langle (f(x) - m(x))  (f(x') - m(x')) \right\rangle \equiv k(x, x')$, where $k(x,x')$ is called the covariance function or kernel. For a discrete set of measurements
%\begin{equation}
%\mathbf{y} = f(\mathbf{x}) + n(\mathbf{x}),
%\end{equation}
%where $n(x)$ is additive Gaussian distributed noise with mean 0 and covariance matrix $N_{pq} \equiv \langle n(x_p)n(x_q) \rangle$, the posterior mean at some requested set of points $\mathbf{x}_*$ is just the mean of the distribution conditioned on $\mathbf{y}$,
%\begin{equation}
%\langle f(\mathbf{x}_*) \rangle = m(\mathbf{x}_*) + k(\mathbf{x}_*, \mathbf{x}) \left( k(\mathbf{x}, \mathbf{x}) + N \right)^{-1} \mathbf{y}. \label{conditional_mean}
%\end{equation}
%The only unknown in Eq. \ref{conditional_mean} is the shape of the kernel $k(x, x')$, and so with Gaussian processes the task is to correctly model the covariance and then optimize its free parameters. Furthermore, since $k(x, x')$ is usually chosen to have some simple analytic form, the derivative of Eq. \ref{conditional_mean} with respect to the evaluation points $\mathbf{x}_*$ can be easily calculated as
%\begin{equation}
%\frac{\partial \langle f(\mathbf{x}_*) \rangle}{\partial \mathbf{x}_*} = \frac{\partial m(\mathbf{x}_*)}{\partial \mathbf{x}_*} + \frac{\partial k(\mathbf{x}_*, \mathbf{x})}{\partial \mathbf{x}_*} \left( k(\mathbf{x}, \mathbf{x}) + N \right)^{-1} \mathbf{y}. \label{d_of_cm}
%\end{equation}

\section{High-resolution simulations}
\label{ch:signal:sec:sims}

\begin{figure} % not h only
\begin{center}
\includegraphics[width=\textwidth]{figures/subgrid/dndm_1Gpc_8192_z2.png}%
\caption{The mass function of a 1 Gpc simulation at redshift 2, with 0.125 Mpc resolution.}
\label{musicdndm}
\end{center}
\end{figure}

The code modifications described in Section \ref{ch:signal:sec:music} have allowed us to compute a set of high-resolution simulations, targeting $10^9~M_\odot$ halos (following the discussion of Section \ref{ch:signal:sec:intro}), in a cosmological volume. We compute (1024 Mpc)$^3$ periodic cubic boxes at redshifts 0, 1, and 2, on an $8192^3$ grid, with 0.125 Mpc resolution. This results in a 30 cell of halo $1.97 \times 10^{9}~M_\odot$ and 100 cell halo of $6.58 \times 10^{9}~M_\odot$. In Figure \ref{musicslice}, we show a visualization of a thin slice through the entire 1 Gpc simulation volume at redshift 2. 

In Figure \ref{musicdndm}, we show the mass function of the redshift 2 simulation, compared to the \citeauthor{tinker2008} universal HMF, as well as the mass limits mentioned above. We observe a departure from the expected power law behaviour in the tail starting at about $2.5 \times 10^{9}~M_\odot$. However, we see from Figure \ref{f_hi_of_mh} that even a sharp mass cut at this halo mass would resolve within $1-2 \%$ of the 21 cm LIM flux.

\section{Results}
\label{ch:signal:sec:results}

In practice, measuring the bias parameters with the boxlet Peack-Background Split (PBS) estimator is a competition between choosing the largest number of boxlets to reduce the error bars on the fit while ensuring that $R(M)/l \ll 1$, where $R(M)$ is top hat Lagriangian radius of the halo of mass $M$, to ensure that mixings between the bias parameters introduced by the smoothing do not pollute the results (as discussed in Refs. \citep{biasreview} and \citep{modietal2017}). Furthermore, the largest mass halos  have a very small number density and Poissonian shot noise is difficult to overcome for this estimator. Therefore we choose to divide by a factor of $L/l = 16$, giving $(R(M)/l) \simeq .2$ for the $\sim 13.0$ Mpc radii of the largest halos in the redshift 2 box, $M \simeq 10^{14} M_\odot$. Although, by relative convergence tests we find that $R(M)/l \leq .1$ is a good rule of thumb therefore we apply several techniques to mitigate these effects for the highest mass bins.

For our direct measurements of the halo mass function (HMF) and bias we divide the range $[2\times 10^9, 1\times 10^{14}]~M_\odot$ into 25 bins evenly spaced in $\ln{M}$ (the lower bound corresponds to the mass of a 30 cell halo). However, to mitigate high mass shot noise we combine the last three bins and the two bins before that into two seperate, producing 22 bins with bin edges at . Secondly, to mitigate mixing effects for the direct measurements, for these two last bins we measure the bias in boxlets of size $L/l = 8$ which produces larger error bars but a convervative estimate for the mean. Furthermore, for the subgrid field we are not interested in accurately modeling the HMF at high masses, since these will be captured exactly in the base simulation. The high masses serve only to anchor the exponential cut off of the HMF in the fit. In production for wide-field surveys this will not be a limitation for the technique, since the simulated volumes are expected to be several factors larger than our 1 Gpc testing and validation simulations.

For this analysis, we first measure the bias directly in the bins mentioned above using the bias estimator discussed in Section \ref{ch:signal:sec:epbs}. In each boxlet we then fit the HMF using Eq. \ref{aemulus_hmf}, using only the high mass bins after which the bias estimator can be applied to the any mass. We estimate the variance in the bins with a jacknife resampling by a factor 4. Any bins containing no halos are considered to have infinite variance and are therefore excluded from the fit.

Interestingly, we find in studying  $N_i(\Delta M)/l^3$ as a function of the averaged fields $\{\overline{\Delta}\}$ that the distribution becomes bi- and even tri-modal for halos of intermediate masses \citep{BAM}. This is because the $($64 Mpc$)^3$ regions we consider are small enough to select either clustered regions or voids. Still, for the perturbation theory framework we are working in, we are interested the average bias throughout the entire simulation volume.

\section{Conclusion}
\label{ch:signal:sec:conclusion}

In this chapter, we have developped a simulation and analysis framework for fast and accurate mocks for 21 cm line intensity mapping (LIM). In Section \ref{ch:signal:sec:music}, we described  and validated our modification of the Peak Patch code to use the Multi-Scale Initial Conditions (MUSIC) code \citep{music} to allow us to generate coherent and parallelized initial conditions on the fly. This has permitted us to generate high resolution simulations in a cosmological volume (Section \ref{ch:signal:sec:sims}), allowing us resolve up to a few percent the entire population of halos contributing to the 21 cm LIM signal. Using the Peak-Background Split tools developped in Section \ref{ch:signal:sec:epbs}, in Section \ref{ch:signal:sec:results} we performed a detailed analysis of the up-to second order Lagrangian bias of this large halo population with special attention the low mass tail of the halo mass function, as is relevant for the Lagrangian perturbation scheme employed by Peak Patch. We then validated a novel extrapolation method forming the foundation of a subgrid field biasing scheme for fast and accurate mocks of 21 cm LIM.

While we have focused on the specific case of 21 cm LIM the code modification of Section \ref{ch:signal:sec:music} is a useful tool for mock catalog techniques in general, since for non-cubic survey geometries (e.g. pencil beam surveys) computational power can be focused on generating independent realizations. The issue of the contribution of the low mass tail is one that needs to be addressed for the LIM surveys in general \citep{statusreport}, so we expect the bias results to be relevant for surveys targeting other spectral lines.

In Section \ref{ch:signal:sec:results}, we focused on the bias as a function of halo mass as a proxy for HI mass, and did not discuss the baryonic physics underlying this relation. While in Section \ref{ch:signal:sec:intro} we presented several prescriptions for the halo to HI mass relation, whose functional forms should be predictive on large scales, these simple mean relations are sure to underestimate the scatter as well as environmental and time dependence. Indeed Ref. \cite{illustristng21cm} found in high-resolution hydrodynamic simulations that ``painting on'' HI to the centre of dark matter halos produces a spurriously large shot noise tail since the feedback cycle causes the average distribution of HI gas to be more diffuse. However, this issue can be solved in mocks by adopting a halo occupation distribution (HOD) \citep{maneraetal2013} to distribute the gas around some profile. These considerations, therefore, demonstrate the power and flexibility of the Peak Patch plus subgrid approach for modeling and fitting a wide variety of cosmological and astrophysical effects.